{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282bfa95-c716-416f-824c-695d9ce421ac",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba355a35-b62a-4797-9ebd-acfebf3b65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt comet_ml  # install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee57fe-0559-4057-9525-641f43979d63",
   "metadata": {},
   "source": [
    "## Intall Pytorch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c296f6-9718-42bb-a87d-f3ef6024ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (0.17.2)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.2.2-cp311-cp311-macosx_10_13_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85c45b-bded-4697-a84b-f89b2c08c24b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e401722a-bbb0-48d9-9f13-7666d3a531ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sathya/Desktop/Learning/Image Recog/YoloV5/YoloV5_Mask/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sathya/opt/anaconda3/envs/YOLOV5/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab0bde8-f47e-4600-bc6e-fded94982155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: cannot change to '/Users/sathya/Desktop/Learning/Image': No such file or directory\n",
      "YOLOv5 üöÄ 2024-11-19 Python-3.11.10 torch-2.2.2 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ‚úÖ (8 CPUs, 16.0 GB RAM, 478.8/926.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5f0e9-fadb-4933-907b-7e5843f88639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, trust_repo=True)  # or yolov5n - yolov5x6 or custom\n",
    "im = 'yolov5/data/images/bus.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model(im)  # inference\n",
    "results.print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca7da91-d489-42b5-9c87-3adf1d724486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "fatal: cannot change to '/Users/sathya/Desktop/Learning/Image': No such file or directory\n",
      "YOLOv5 üöÄ 2024-11-19 Python-3.11.10 torch-2.2.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "image 1/2 /Users/sathya/Desktop/Learning/Image Recog/YoloV5/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 339.6ms\n",
      "image 2/2 /Users/sathya/Desktop/Learning/Image Recog/YoloV5/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 260.8ms\n",
      "Speed: 0.9ms pre-process, 300.2ms inference, 5.4ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b4277-7b7f-4b46-99f8-1cdc567e4ecd",
   "metadata": {},
   "source": [
    "## Download COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "022920cc-6237-409a-a960-2c7d9a6ab99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 780M/780M [00:34<00:00, 23.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download COCO val\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ebbc7-a764-4bae-96ee-96e9003697a2",
   "metadata": {},
   "source": [
    "### Optional validation using the detect.py and train.py scripts on the coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51337891-7bc6-472b-851d-2adb89ad138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --source '/Users/sathya/Desktop/Learning/Image Recog/YoloV5/datasets/coco/images/val2017' --img 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b718a-e732-45d5-b2d5-803dde391611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b486151-567a-49cc-80d4-b0a32523d23b",
   "metadata": {},
   "source": [
    "### Generate the labels for the Mask at a random probability of 0.3 on all the existing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12334d76-a670-4dc5-b47f-98b18c785cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Filtered and removed files saved to respective folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder paths\n",
    "input_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5/YoloV5_Mask/datasets/coco/labels/val2017\"  # Folder containing the original text files\n",
    "filtered_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5/YoloV5_Mask/datasets/coco/labels/labels_with_out_mask\"  # Folder to save filtered files\n",
    "removed_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5/YoloV5_Mask/datasets/coco/labels/mask\"  # Folder to save removed rows\n",
    "\n",
    "# Ensure the output folders exist\n",
    "os.makedirs(filtered_folder, exist_ok=True)\n",
    "os.makedirs(removed_folder, exist_ok=True)\n",
    "\n",
    "# Probability threshold\n",
    "threshold = 0.3\n",
    "\n",
    "# Process each text file in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):  # Process only .txt files\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Read the text file into a DataFrame\n",
    "        data = pd.read_csv(input_file_path, delimiter=\"\\t\", header=None, names=[\"Row\"], dtype=str)\n",
    "\n",
    "        # Generate random probabilities for each row\n",
    "        data['Random_Probability'] = np.random.rand(len(data))\n",
    "\n",
    "        # Filter rows based on the threshold\n",
    "        filtered_data = data[data['Random_Probability'] >= threshold].drop(columns=['Random_Probability'])\n",
    "        removed_data = data[data['Random_Probability'] < threshold].drop(columns=['Random_Probability'])\n",
    "\n",
    "        # Save the filtered rows to the filtered folder\n",
    "        filtered_file_path = os.path.join(filtered_folder, filename)\n",
    "        filtered_data.to_csv(filtered_file_path, index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "        # Save the removed rows to the removed folder\n",
    "        removed_file_path = os.path.join(removed_folder, filename)\n",
    "        removed_data.to_csv(removed_file_path, index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "print(\"Processing complete. Filtered and removed files saved to respective folders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a8a2e-0fed-4ef3-a3b6-a3f9e272dd8d",
   "metadata": {},
   "source": [
    "### Based on the mask labels generated in the previous step, generate the respective mask images in PNG format. Ensure that each mask image has the same dimensions as the corresponding input original image. Store all the generated mask images in a designated folder for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248c3c3-fb99-410f-a5d7-f97275ed8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Folder paths\n",
    "image_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5/YoloV5_Mask/datasets/coco/images/val2017\"  # Folder containing images\n",
    "bbox_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5/YoloV5_Mask/datasets/coco/labels/mask\"  # Folder containing bounding box txt files\n",
    "output_folder = \"/Users/sathya/Desktop/Learning/Image_Recog/YoloV5_Mask/YoloV5/datasets/coco/images/mask\"  # Folder to save generated mask images\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each image in the image folder\n",
    "for image_filename in os.listdir(image_folder):\n",
    "    if image_filename.endswith((\".jpg\", \".png\")):  # Process only image files\n",
    "        # Get corresponding bounding box file\n",
    "        base_name = os.path.splitext(image_filename)[0]\n",
    "        bbox_file_path = os.path.join(bbox_folder, f\"{base_name}.txt\")\n",
    "\n",
    "        # Skip if bounding box file doesn't exist\n",
    "        if not os.path.exists(bbox_file_path):\n",
    "            print(f\"Bounding box file not found for {image_filename}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load image and get dimensions\n",
    "        image_path = os.path.join(image_folder, image_filename)\n",
    "        image = Image.open(image_path)\n",
    "        image_width, image_height = image.size\n",
    "\n",
    "        # Create a blank grayscale mask\n",
    "        mask = Image.new(\"L\", (image_width, image_height), 255)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        # Read bounding box data from the text file\n",
    "        with open(bbox_file_path, \"r\") as bbox_file:\n",
    "            for line in bbox_file:\n",
    "                values = line.strip().split()\n",
    "                if len(values) != 5:\n",
    "                    continue  # Skip invalid lines\n",
    "                _, x_center, y_center, width, height = map(float, values)\n",
    "\n",
    "                # Convert normalized coordinates to pixel coordinates\n",
    "                box_width = width * image_width\n",
    "                box_height = height * image_height\n",
    "                x_min = (x_center * image_width) - (box_width / 2)\n",
    "                y_min = (y_center * image_height) - (box_height / 2)\n",
    "                x_max = x_min + box_width\n",
    "                y_max = y_min + box_height\n",
    "\n",
    "                # Draw rectangle on the mask (0 for inside the bounding box)\n",
    "                draw.rectangle([x_min, y_min, x_max, y_max], fill=0)\n",
    "\n",
    "        # Save the mask in the output folder as PNG\n",
    "        mask_output_path = os.path.join(output_folder, f\"{base_name}_mask.png\")\n",
    "        mask.save(mask_output_path)\n",
    "        print(f\"Mask saved for {image_filename} at {mask_output_path}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
